PCC 比赛思路

作为一个 local cache 的坚定拥护者，在第一眼看到这次比赛题目的时候，就已经决定了要用 local cache 来做。
唯一的问题是，Java 技术圈里，local cache 不少，但真正适合大量数据的却不多。
曾经在线上环境用过 ehcache，也用过 hazelcast ，非线上环境尝试过 mapdb 。这一次，想试试号称为“高频交易”而生的 Chronicle-Map 。
选中 Chronicle-Map 是因为：
1. Map 接口，使用简单
2. off heap，无 gc 压力
3. mmap 文件，支持重启不丢失数据
为了解决 value 长度差别过大，导致写入文件性能低下的问题，我在原生的 Chronicle-Map 外面包了一层 ListmapService，用多个不同的 map 来存储不同 value 长度的数据。于是这个方案的重点就变成了如何根据数据的分布选择合适的 map size 的问题了。
用 Springboot 写微服务如行云流水，半天时间连 test case 都写好了。但写到 cursor 翻页的地方，我才反应过来，简单粗暴的的数组并不是一个很适合存储 like 列表的数据结构。果然，在后面的导入数据环节，因为数据结构不够高效，导致导入速度非常缓慢，简单的做了一下并发导入的优化，但效果依然不够理想。
比赛结束后，回过头来想想，这样的比赛对于码农来说确实非常有帮助，既锻炼了写码速度，又开拓了架构眼界。唯一不足的是，很多参赛方案最后都演变成了开源组件选择比赛，选 nginx，选 redis，选 leveldb，选来选去，最终也没有选出一个因为所以来。
